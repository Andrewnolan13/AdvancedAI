{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa8568a4",
      "metadata": {
        "id": "aa8568a4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing._data import BaseEstimator, TransformerMixin, OneToOneFeatureMixin\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "790c116c",
      "metadata": {
        "id": "790c116c",
        "outputId": "9363089f-bc1c-4e83-a1f8-2255698903f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>Usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Training</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Training</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Training</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35887 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion        Usage                                             pixels\n",
              "0            0     Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1            0     Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2            2     Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3            4     Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4            6     Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
              "...        ...          ...                                                ...\n",
              "35882        6  PrivateTest  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
              "35883        3  PrivateTest  178 174 172 173 181 188 191 194 196 199 200 20...\n",
              "35884        0  PrivateTest  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
              "35885        3  PrivateTest  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
              "35886        2  PrivateTest  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
              "\n",
              "[35887 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TrainingData = pd.read_csv('../data/01 Raw/icml_face_data.csv')\n",
        "TrainingData\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d06df5",
      "metadata": {
        "id": "e1d06df5"
      },
      "outputs": [],
      "source": [
        "TrainingData.columns = TrainingData.columns.map(lambda x: x.lower().strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84aeee6b",
      "metadata": {
        "id": "84aeee6b",
        "outputId": "0c6301a5-6300-4158-bcae-6026c73ad934"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Training</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Training</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Training</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35887 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion        usage                                             pixels\n",
              "0            0     Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1            0     Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2            2     Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3            4     Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4            6     Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
              "...        ...          ...                                                ...\n",
              "35882        6  PrivateTest  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
              "35883        3  PrivateTest  178 174 172 173 181 188 191 194 196 199 200 20...\n",
              "35884        0  PrivateTest  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
              "35885        3  PrivateTest  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
              "35886        2  PrivateTest  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
              "\n",
              "[35887 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TrainingData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdf4a99e",
      "metadata": {
        "id": "fdf4a99e"
      },
      "outputs": [],
      "source": [
        "FinalTestData = pd.read_pickle('../data/02 Processed/testData.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e555a8",
      "metadata": {
        "id": "e7e555a8",
        "outputId": "d9b62d66-fb0e-4f8c-8233-51b8593a640d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23022</th>\n",
              "      <td>3</td>\n",
              "      <td>Training</td>\n",
              "      <td>226 220 207 191 178 162 158 146 168 139 146 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233</th>\n",
              "      <td>2</td>\n",
              "      <td>Training</td>\n",
              "      <td>235 236 233 141 92 116 103 80 67 75 71 55 65 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15400</th>\n",
              "      <td>3</td>\n",
              "      <td>Training</td>\n",
              "      <td>69 63 58 52 48 44 45 49 55 61 47 39 100 70 27 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10792</th>\n",
              "      <td>3</td>\n",
              "      <td>Training</td>\n",
              "      <td>168 161 166 165 165 177 181 180 174 171 166 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27856</th>\n",
              "      <td>3</td>\n",
              "      <td>Training</td>\n",
              "      <td>94 104 105 119 120 128 160 158 160 158 159 149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3387</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>45 41 44 47 49 50 69 113 143 143 145 152 161 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33620</th>\n",
              "      <td>6</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>214 219 221 220 221 220 220 223 208 131 107 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26225</th>\n",
              "      <td>6</td>\n",
              "      <td>Training</td>\n",
              "      <td>157 114 63 18 10 10 23 11 8 24 26 11 11 11 19 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34258</th>\n",
              "      <td>2</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>115 120 125 130 138 143 145 146 148 148 147 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7861</th>\n",
              "      <td>5</td>\n",
              "      <td>Training</td>\n",
              "      <td>102 103 96 94 103 79 59 50 46 62 75 71 69 90 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7178 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion        usage                                             pixels\n",
              "23022        3     Training  226 220 207 191 178 162 158 146 168 139 146 14...\n",
              "2233         2     Training  235 236 233 141 92 116 103 80 67 75 71 55 65 6...\n",
              "15400        3     Training  69 63 58 52 48 44 45 49 55 61 47 39 100 70 27 ...\n",
              "10792        3     Training  168 161 166 165 165 177 181 180 174 171 166 16...\n",
              "27856        3     Training  94 104 105 119 120 128 160 158 160 158 159 149...\n",
              "...        ...          ...                                                ...\n",
              "3387         0     Training  45 41 44 47 49 50 69 113 143 143 145 152 161 1...\n",
              "33620        6  PrivateTest  214 219 221 220 221 220 220 223 208 131 107 11...\n",
              "26225        6     Training  157 114 63 18 10 10 23 11 8 24 26 11 11 11 19 ...\n",
              "34258        2  PrivateTest  115 120 125 130 138 143 145 146 148 148 147 14...\n",
              "7861         5     Training  102 103 96 94 103 79 59 50 46 62 75 71 69 90 1...\n",
              "\n",
              "[7178 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FinalTestData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92dd9eec",
      "metadata": {
        "id": "92dd9eec",
        "outputId": "a9c9a1bc-35a4-40f6-97ff-835576506453"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " Usage\n",
              "Training       28709\n",
              "PublicTest      3589\n",
              "PrivateTest     3589\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TrainingData[' Usage'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20112027",
      "metadata": {
        "id": "20112027"
      },
      "outputs": [],
      "source": [
        "TrainingData = pd.read_pickle('../data/02 Processed/train.pkl')\n",
        "FinalTestData = pd.read_pickle('../data/02 Processed/testData.pkl')\n",
        "FinalTestData.drop(columns = 'usage', inplace = True)\n",
        "# s = TrainingData.iloc[:1000].copy()\n",
        "# del TrainingData\n",
        "# TrainingData = s.copy()\n",
        "# del s\n",
        "\n",
        "FinalTestData.shape, TrainingData.shape\n",
        "TrainingDataCheckPoint = TrainingData.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a6d3f4",
      "metadata": {
        "id": "25a6d3f4"
      },
      "outputs": [],
      "source": [
        "big,small = train_test_split(TrainingData, test_size=0.02, stratify=TrainingData['emotion'], random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c602de3d",
      "metadata": {
        "id": "c602de3d",
        "outputId": "24cf9228-fa15-40f0-8107-4d429cfddd75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='emotion'>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "small.emotion.value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27394554",
      "metadata": {
        "id": "27394554",
        "outputId": "f44f835e-9c7e-4a02-bd40-3c6c8a0e038a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='emotion'>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGrCAYAAAAirYa4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzgElEQVR4nO3de3RU5b3G8ScXcgMmEDAJkRDSopJULhIkjKICpowYe0CjBYsYIeKBk1hJKlS6OIGCLZaWSyzB1CKEVjlcTqsHCCZgKNCScAtEkZtgaZNTnAAFMoKQBDLnj67sw5SEGhAH3nw/a+21mP3+9ju//S4NDzt7z/i43W63AAAADOPr7QYAAABuBEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR/L3dgDfV19fr2LFjatu2rXx8fLzdDgAA+BLcbrc+//xzRUVFyde36es1LTrkHDt2TNHR0d5uAwAAXIPKykp17ty5yfEWHXLatm0r6R+LZLPZvNwNAAD4Mlwul6Kjo62/x5vSokNOw6+obDYbIQcAgFvMv7rVhBuPAQCAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABipWSGna9eu8vHxuWJLT0+XJF24cEHp6enq0KGD2rRpo5SUFFVVVXnMUVFRoeTkZIWEhCg8PFyTJk3SxYsXPWo2bdqkPn36KDAwUN26dVN+fv4VveTm5qpr164KCgpSYmKiduzY0cxTBwAAJmtWyNm5c6c+++wza9uwYYMk6amnnpIkZWZmas2aNVq1apU2b96sY8eO6YknnrCOv3TpkpKTk1VbW6uSkhItXbpU+fn5ys7OtmqOHj2q5ORkDRo0SOXl5Zo4caKef/55FRUVWTUrVqxQVlaWpk2bpt27d6tXr15yOBw6fvz4dS0GAAAwh4/b7XZf68ETJ07U2rVrdfjwYblcLt12221atmyZnnzySUnSwYMHFRcXp9LSUvXv31/vv/++HnvsMR07dkwRERGSpLy8PP3whz/UiRMnFBAQoB/+8IcqKCjQxx9/bL3PyJEjdebMGRUWFkqSEhMTde+992rBggWSpPr6ekVHR+vFF1/UK6+88qX7d7lcCg0NVXV1tWw227Uug7q+UnDNx94If3kt2dstWFibpt1Ma3MzrYvE2lwNa9M01qZxN9O6SF/N2nzZv7+v+Z6c2tpavf322xo7dqx8fHxUVlamuro6JSUlWTXdu3dXly5dVFpaKkkqLS1Vjx49rIAjSQ6HQy6XS/v27bNqLp+joaZhjtraWpWVlXnU+Pr6KikpyappSk1NjVwul8cGAADMdM0h57333tOZM2f03HPPSZKcTqcCAgLUrl07j7qIiAg5nU6r5vKA0zDeMHa1GpfLpfPnz+vkyZO6dOlSozUNczRl1qxZCg0Ntbbo6OhmnTMAALh1XHPIeeuttzR06FBFRUV9lf3cUFOmTFF1dbW1VVZWerslAABwg/hfy0F//etf9cEHH+j3v/+9tS8yMlK1tbU6c+aMx9WcqqoqRUZGWjX//BRUw9NXl9f88xNZVVVVstlsCg4Olp+fn/z8/BqtaZijKYGBgQoMDGzeyQIAgFvSNV3JWbJkicLDw5Wc/P83DyUkJKhVq1YqLi629h06dEgVFRWy2+2SJLvdrr1793o8BbVhwwbZbDbFx8dbNZfP0VDTMEdAQIASEhI8aurr61VcXGzVAAAANPtKTn19vZYsWaLU1FT5+///4aGhoUpLS1NWVpbCwsJks9n04osvym63q3///pKkIUOGKD4+XqNHj9bs2bPldDo1depUpaenW1dYxo8frwULFmjy5MkaO3asNm7cqJUrV6qg4P/vDs/KylJqaqr69u2rfv36af78+Tp37pzGjBlzvesBAAAM0eyQ88EHH6iiokJjx469YmzevHny9fVVSkqKampq5HA4tHDhQmvcz89Pa9eu1YQJE2S329W6dWulpqZqxowZVk1sbKwKCgqUmZmpnJwcde7cWYsWLZLD4bBqRowYoRMnTig7O1tOp1O9e/dWYWHhFTcjAwCAlqvZIWfIkCFq6qN1goKClJubq9zc3CaPj4mJ0bp16676HgMHDtSePXuuWpORkaGMjIx/3TAAAGiR+O4qAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJGaHXL+9re/6ZlnnlGHDh0UHBysHj16aNeuXda42+1Wdna2OnXqpODgYCUlJenw4cMec5w6dUqjRo2SzWZTu3btlJaWprNnz3rUfPTRR3rggQcUFBSk6OhozZ49+4peVq1ape7duysoKEg9evTQunXrmns6AADAUM0KOadPn9b999+vVq1a6f3339f+/fs1Z84ctW/f3qqZPXu2Xn/9deXl5Wn79u1q3bq1HA6HLly4YNWMGjVK+/bt04YNG7R27Vpt2bJFL7zwgjXucrk0ZMgQxcTEqKysTD//+c81ffp0vfnmm1ZNSUmJnn76aaWlpWnPnj0aPny4hg8fro8//vh61gMAABjCvznFP/vZzxQdHa0lS5ZY+2JjY60/u91uzZ8/X1OnTtWwYcMkSb/5zW8UERGh9957TyNHjtSBAwdUWFionTt3qm/fvpKkX/7yl3r00Uf1i1/8QlFRUXrnnXdUW1urxYsXKyAgQN/61rdUXl6uuXPnWmEoJydHjzzyiCZNmiRJmjlzpjZs2KAFCxYoLy/v+lYFAADc8pp1JWf16tXq27evnnrqKYWHh+uee+7Rr3/9a2v86NGjcjqdSkpKsvaFhoYqMTFRpaWlkqTS0lK1a9fOCjiSlJSUJF9fX23fvt2qefDBBxUQEGDVOBwOHTp0SKdPn7ZqLn+fhpqG92lMTU2NXC6XxwYAAMzUrJDz5z//WW+88YbuuOMOFRUVacKECfr+97+vpUuXSpKcTqckKSIiwuO4iIgIa8zpdCo8PNxj3N/fX2FhYR41jc1x+Xs0VdMw3phZs2YpNDTU2qKjo5tz+gAA4BbSrJBTX1+vPn366Kc//anuuecevfDCCxo3btwt8+uhKVOmqLq62toqKyu93RIAALhBmhVyOnXqpPj4eI99cXFxqqiokCRFRkZKkqqqqjxqqqqqrLHIyEgdP37cY/zixYs6deqUR01jc1z+Hk3VNIw3JjAwUDabzWMDAABmalbIuf/++3Xo0CGPfZ988oliYmIk/eMm5MjISBUXF1vjLpdL27dvl91ulyTZ7XadOXNGZWVlVs3GjRtVX1+vxMREq2bLli2qq6uzajZs2KC77rrLepLLbrd7vE9DTcP7AACAlq1ZISczM1Pbtm3TT3/6Ux05ckTLli3Tm2++qfT0dEmSj4+PJk6cqFdffVWrV6/W3r179eyzzyoqKkrDhw+X9I8rP4888ojGjRunHTt2aOvWrcrIyNDIkSMVFRUlSfre976ngIAApaWlad++fVqxYoVycnKUlZVl9fLSSy+psLBQc+bM0cGDBzV9+nTt2rVLGRkZX9HSAACAW1mzHiG/99579e6772rKlCmaMWOGYmNjNX/+fI0aNcqqmTx5ss6dO6cXXnhBZ86c0YABA1RYWKigoCCr5p133lFGRoYefvhh+fr6KiUlRa+//ro1HhoaqvXr1ys9PV0JCQnq2LGjsrOzPT5L57777tOyZcs0depU/ehHP9Idd9yh9957T3fffff1rAcAADBEs0KOJD322GN67LHHmhz38fHRjBkzNGPGjCZrwsLCtGzZsqu+T8+ePfXHP/7xqjVPPfWUnnrqqas3DAAAWiS+uwoAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgpGaFnOnTp8vHx8dj6969uzV+4cIFpaenq0OHDmrTpo1SUlJUVVXlMUdFRYWSk5MVEhKi8PBwTZo0SRcvXvSo2bRpk/r06aPAwEB169ZN+fn5V/SSm5urrl27KigoSImJidqxY0dzTgUAABiu2VdyvvWtb+mzzz6ztj/96U/WWGZmptasWaNVq1Zp8+bNOnbsmJ544glr/NKlS0pOTlZtba1KSkq0dOlS5efnKzs726o5evSokpOTNWjQIJWXl2vixIl6/vnnVVRUZNWsWLFCWVlZmjZtmnbv3q1evXrJ4XDo+PHj17oOAADAMM0OOf7+/oqMjLS2jh07SpKqq6v11ltvae7cuRo8eLASEhK0ZMkSlZSUaNu2bZKk9evXa//+/Xr77bfVu3dvDR06VDNnzlRubq5qa2slSXl5eYqNjdWcOXMUFxenjIwMPfnkk5o3b57Vw9y5czVu3DiNGTNG8fHxysvLU0hIiBYvXvxVrAkAADBAs0PO4cOHFRUVpW984xsaNWqUKioqJEllZWWqq6tTUlKSVdu9e3d16dJFpaWlkqTS0lL16NFDERERVo3D4ZDL5dK+ffusmsvnaKhpmKO2tlZlZWUeNb6+vkpKSrJqmlJTUyOXy+WxAQAAMzUr5CQmJio/P1+FhYV64403dPToUT3wwAP6/PPP5XQ6FRAQoHbt2nkcExERIafTKUlyOp0eAadhvGHsajUul0vnz5/XyZMndenSpUZrGuZoyqxZsxQaGmpt0dHRzTl9AABwC/FvTvHQoUOtP/fs2VOJiYmKiYnRypUrFRwc/JU391WbMmWKsrKyrNcul4ugAwCAoa7rEfJ27drpzjvv1JEjRxQZGana2lqdOXPGo6aqqkqRkZGSpMjIyCuetmp4/a9qbDabgoOD1bFjR/n5+TVa0zBHUwIDA2Wz2Tw2AABgpusKOWfPntWnn36qTp06KSEhQa1atVJxcbE1fujQIVVUVMhut0uS7Ha79u7d6/EU1IYNG2Sz2RQfH2/VXD5HQ03DHAEBAUpISPCoqa+vV3FxsVUDAADQrJDz8ssva/PmzfrLX/6ikpISPf744/Lz89PTTz+t0NBQpaWlKSsrS3/4wx9UVlamMWPGyG63q3///pKkIUOGKD4+XqNHj9aHH36ooqIiTZ06Venp6QoMDJQkjR8/Xn/+8581efJkHTx4UAsXLtTKlSuVmZlp9ZGVlaVf//rXWrp0qQ4cOKAJEybo3LlzGjNmzFe4NAAA4FbWrHty/vd//1dPP/20/v73v+u2227TgAEDtG3bNt12222SpHnz5snX11cpKSmqqamRw+HQwoULreP9/Py0du1aTZgwQXa7Xa1bt1ZqaqpmzJhh1cTGxqqgoECZmZnKyclR586dtWjRIjkcDqtmxIgROnHihLKzs+V0OtW7d28VFhZecTMyAABouZoVcpYvX37V8aCgIOXm5io3N7fJmpiYGK1bt+6q8wwcOFB79uy5ak1GRoYyMjKuWgMAAFouvrsKAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKTrCjmvvfaafHx8NHHiRGvfhQsXlJ6erg4dOqhNmzZKSUlRVVWVx3EVFRVKTk5WSEiIwsPDNWnSJF28eNGjZtOmTerTp48CAwPVrVs35efnX/H+ubm56tq1q4KCgpSYmKgdO3Zcz+kAAACDXHPI2blzp371q1+pZ8+eHvszMzO1Zs0arVq1Sps3b9axY8f0xBNPWOOXLl1ScnKyamtrVVJSoqVLlyo/P1/Z2dlWzdGjR5WcnKxBgwapvLxcEydO1PPPP6+ioiKrZsWKFcrKytK0adO0e/du9erVSw6HQ8ePH7/WUwIAAAa5ppBz9uxZjRo1Sr/+9a/Vvn17a391dbXeeustzZ07V4MHD1ZCQoKWLFmikpISbdu2TZK0fv167d+/X2+//bZ69+6toUOHaubMmcrNzVVtba0kKS8vT7GxsZozZ47i4uKUkZGhJ598UvPmzbPea+7cuRo3bpzGjBmj+Ph45eXlKSQkRIsXL76e9QAAAIa4ppCTnp6u5ORkJSUleewvKytTXV2dx/7u3burS5cuKi0tlSSVlpaqR48eioiIsGocDodcLpf27dtn1fzz3A6Hw5qjtrZWZWVlHjW+vr5KSkqyahpTU1Mjl8vlsQEAADP5N/eA5cuXa/fu3dq5c+cVY06nUwEBAWrXrp3H/oiICDmdTqvm8oDTMN4wdrUal8ul8+fP6/Tp07p06VKjNQcPHmyy91mzZunHP/7xlztRAABwS2vWlZzKykq99NJLeueddxQUFHSjerphpkyZourqamurrKz0dksAAOAGaVbIKSsr0/Hjx9WnTx/5+/vL399fmzdv1uuvvy5/f39FRESotrZWZ86c8TiuqqpKkZGRkqTIyMgrnrZqeP2vamw2m4KDg9WxY0f5+fk1WtMwR2MCAwNls9k8NgAAYKZmhZyHH35Ye/fuVXl5ubX17dtXo0aNsv7cqlUrFRcXW8ccOnRIFRUVstvtkiS73a69e/d6PAW1YcMG2Ww2xcfHWzWXz9FQ0zBHQECAEhISPGrq6+tVXFxs1QAAgJatWffktG3bVnfffbfHvtatW6tDhw7W/rS0NGVlZSksLEw2m00vvvii7Ha7+vfvL0kaMmSI4uPjNXr0aM2ePVtOp1NTp05Venq6AgMDJUnjx4/XggULNHnyZI0dO1YbN27UypUrVVBQYL1vVlaWUlNT1bdvX/Xr10/z58/XuXPnNGbMmOtaEAAAYIZm33j8r8ybN0++vr5KSUlRTU2NHA6HFi5caI37+flp7dq1mjBhgux2u1q3bq3U1FTNmDHDqomNjVVBQYEyMzOVk5Ojzp07a9GiRXI4HFbNiBEjdOLECWVnZ8vpdKp3794qLCy84mZkAADQMl13yNm0aZPH66CgIOXm5io3N7fJY2JiYrRu3bqrzjtw4EDt2bPnqjUZGRnKyMj40r0CAICWg++uAgAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABipWSHnjTfeUM+ePWWz2WSz2WS32/X+++9b4xcuXFB6ero6dOigNm3aKCUlRVVVVR5zVFRUKDk5WSEhIQoPD9ekSZN08eJFj5pNmzapT58+CgwMVLdu3ZSfn39FL7m5ueratauCgoKUmJioHTt2NOdUAACA4ZoVcjp37qzXXntNZWVl2rVrlwYPHqxhw4Zp3759kqTMzEytWbNGq1at0ubNm3Xs2DE98cQT1vGXLl1ScnKyamtrVVJSoqVLlyo/P1/Z2dlWzdGjR5WcnKxBgwapvLxcEydO1PPPP6+ioiKrZsWKFcrKytK0adO0e/du9erVSw6HQ8ePH7/e9QAAAIZoVsj5zne+o0cffVR33HGH7rzzTv3kJz9RmzZttG3bNlVXV+utt97S3LlzNXjwYCUkJGjJkiUqKSnRtm3bJEnr16/X/v379fbbb6t3794aOnSoZs6cqdzcXNXW1kqS8vLyFBsbqzlz5iguLk4ZGRl68sknNW/ePKuPuXPnaty4cRozZozi4+OVl5enkJAQLV68+CtcGgAAcCu75ntyLl26pOXLl+vcuXOy2+0qKytTXV2dkpKSrJru3burS5cuKi0tlSSVlpaqR48eioiIsGocDodcLpd1Nai0tNRjjoaahjlqa2tVVlbmUePr66ukpCSrpik1NTVyuVweGwAAMFOzQ87evXvVpk0bBQYGavz48Xr33XcVHx8vp9OpgIAAtWvXzqM+IiJCTqdTkuR0Oj0CTsN4w9jValwul86fP6+TJ0/q0qVLjdY0zNGUWbNmKTQ01Nqio6Obe/oAAOAW0eyQc9ddd6m8vFzbt2/XhAkTlJqaqv3799+I3r5yU6ZMUXV1tbVVVlZ6uyUAAHCD+Df3gICAAHXr1k2SlJCQoJ07dyonJ0cjRoxQbW2tzpw543E1p6qqSpGRkZKkyMjIK56Canj66vKaf34iq6qqSjabTcHBwfLz85Ofn1+jNQ1zNCUwMFCBgYHNPWUAAHALuu7Pyamvr1dNTY0SEhLUqlUrFRcXW2OHDh1SRUWF7Ha7JMlut2vv3r0eT0Ft2LBBNptN8fHxVs3lczTUNMwREBCghIQEj5r6+noVFxdbNQAAAM26kjNlyhQNHTpUXbp00eeff65ly5Zp06ZNKioqUmhoqNLS0pSVlaWwsDDZbDa9+OKLstvt6t+/vyRpyJAhio+P1+jRozV79mw5nU5NnTpV6enp1hWW8ePHa8GCBZo8ebLGjh2rjRs3auXKlSooKLD6yMrKUmpqqvr27at+/fpp/vz5OnfunMaMGfMVLg0AALiVNSvkHD9+XM8++6w+++wzhYaGqmfPnioqKtK3v/1tSdK8efPk6+urlJQU1dTUyOFwaOHChdbxfn5+Wrt2rSZMmCC73a7WrVsrNTVVM2bMsGpiY2NVUFCgzMxM5eTkqHPnzlq0aJEcDodVM2LECJ04cULZ2dlyOp3q3bu3CgsLr7gZGQAAtFzNCjlvvfXWVceDgoKUm5ur3NzcJmtiYmK0bt26q84zcOBA7dmz56o1GRkZysjIuGoNAABoufjuKgAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRmhVyZs2apXvvvVdt27ZVeHi4hg8frkOHDnnUXLhwQenp6erQoYPatGmjlJQUVVVVedRUVFQoOTlZISEhCg8P16RJk3Tx4kWPmk2bNqlPnz4KDAxUt27dlJ+ff0U/ubm56tq1q4KCgpSYmKgdO3Y053QAAIDBmhVyNm/erPT0dG3btk0bNmxQXV2dhgwZonPnzlk1mZmZWrNmjVatWqXNmzfr2LFjeuKJJ6zxS5cuKTk5WbW1tSopKdHSpUuVn5+v7Oxsq+bo0aNKTk7WoEGDVF5erokTJ+r5559XUVGRVbNixQplZWVp2rRp2r17t3r16iWHw6Hjx49fz3oAAABD+DenuLCw0ON1fn6+wsPDVVZWpgcffFDV1dV66623tGzZMg0ePFiStGTJEsXFxWnbtm3q37+/1q9fr/379+uDDz5QRESEevfurZkzZ+qHP/yhpk+froCAAOXl5Sk2NlZz5syRJMXFxelPf/qT5s2bJ4fDIUmaO3euxo0bpzFjxkiS8vLyVFBQoMWLF+uVV1657oUBAAC3tuu6J6e6ulqSFBYWJkkqKytTXV2dkpKSrJru3burS5cuKi0tlSSVlpaqR48eioiIsGocDodcLpf27dtn1Vw+R0NNwxy1tbUqKyvzqPH19VVSUpJV05iamhq5XC6PDQAAmOmaQ059fb0mTpyo+++/X3fffbckyel0KiAgQO3atfOojYiIkNPptGouDzgN4w1jV6txuVw6f/68Tp48qUuXLjVa0zBHY2bNmqXQ0FBri46Obv6JAwCAW8I1h5z09HR9/PHHWr58+VfZzw01ZcoUVVdXW1tlZaW3WwIAADdIs+7JaZCRkaG1a9dqy5Yt6ty5s7U/MjJStbW1OnPmjMfVnKqqKkVGRlo1//wUVMPTV5fX/PMTWVVVVbLZbAoODpafn5/8/PwarWmYozGBgYEKDAxs/gkDAIBbTrOu5LjdbmVkZOjdd9/Vxo0bFRsb6zGekJCgVq1aqbi42Np36NAhVVRUyG63S5Lsdrv27t3r8RTUhg0bZLPZFB8fb9VcPkdDTcMcAQEBSkhI8Kipr69XcXGxVQMAAFq2Zl3JSU9P17Jly/Q///M/atu2rXX/S2hoqIKDgxUaGqq0tDRlZWUpLCxMNptNL774oux2u/r37y9JGjJkiOLj4zV69GjNnj1bTqdTU6dOVXp6unWVZfz48VqwYIEmT56ssWPHauPGjVq5cqUKCgqsXrKyspSamqq+ffuqX79+mj9/vs6dO2c9bQUAAFq2ZoWcN954Q5I0cOBAj/1LlizRc889J0maN2+efH19lZKSopqaGjkcDi1cuNCq9fPz09q1azVhwgTZ7Xa1bt1aqampmjFjhlUTGxurgoICZWZmKicnR507d9aiRYusx8clacSIETpx4oSys7PldDrVu3dvFRYWXnEzMgAAaJmaFXLcbve/rAkKClJubq5yc3ObrImJidG6deuuOs/AgQO1Z8+eq9ZkZGQoIyPjX/YEAABaHr67CgAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGCkZoecLVu26Dvf+Y6ioqLk4+Oj9957z2Pc7XYrOztbnTp1UnBwsJKSknT48GGPmlOnTmnUqFGy2Wxq166d0tLSdPbsWY+ajz76SA888ICCgoIUHR2t2bNnX9HLqlWr1L17dwUFBalHjx5at25dc08HAAAYqtkh59y5c+rVq5dyc3MbHZ89e7Zef/115eXlafv27WrdurUcDocuXLhg1YwaNUr79u3Thg0btHbtWm3ZskUvvPCCNe5yuTRkyBDFxMSorKxMP//5zzV9+nS9+eabVk1JSYmefvpppaWlac+ePRo+fLiGDx+ujz/+uLmnBAAADOTf3AOGDh2qoUOHNjrmdrs1f/58TZ06VcOGDZMk/eY3v1FERITee+89jRw5UgcOHFBhYaF27typvn37SpJ++ctf6tFHH9UvfvELRUVF6Z133lFtba0WL16sgIAAfetb31J5ebnmzp1rhaGcnBw98sgjmjRpkiRp5syZ2rBhgxYsWKC8vLxrWgwAAGCOr/SenKNHj8rpdCopKcnaFxoaqsTERJWWlkqSSktL1a5dOyvgSFJSUpJ8fX21fft2q+bBBx9UQECAVeNwOHTo0CGdPn3aqrn8fRpqGt6nMTU1NXK5XB4bAAAw01cacpxOpyQpIiLCY39ERIQ15nQ6FR4e7jHu7++vsLAwj5rG5rj8PZqqaRhvzKxZsxQaGmpt0dHRzT1FAABwi2hRT1dNmTJF1dXV1lZZWentlgAAwA3ylYacyMhISVJVVZXH/qqqKmssMjJSx48f9xi/ePGiTp065VHT2ByXv0dTNQ3jjQkMDJTNZvPYAACAmb7SkBMbG6vIyEgVFxdb+1wul7Zv3y673S5JstvtOnPmjMrKyqyajRs3qr6+XomJiVbNli1bVFdXZ9Vs2LBBd911l9q3b2/VXP4+DTUN7wMAAFq2Zoecs2fPqry8XOXl5ZL+cbNxeXm5Kioq5OPjo4kTJ+rVV1/V6tWrtXfvXj377LOKiorS8OHDJUlxcXF65JFHNG7cOO3YsUNbt25VRkaGRo4cqaioKEnS9773PQUEBCgtLU379u3TihUrlJOTo6ysLKuPl156SYWFhZozZ44OHjyo6dOna9euXcrIyLj+VQEAALe8Zj9CvmvXLg0aNMh63RA8UlNTlZ+fr8mTJ+vcuXN64YUXdObMGQ0YMECFhYUKCgqyjnnnnXeUkZGhhx9+WL6+vkpJSdHrr79ujYeGhmr9+vVKT09XQkKCOnbsqOzsbI/P0rnvvvu0bNkyTZ06VT/60Y90xx136L333tPdd999TQsBAADM0uyQM3DgQLnd7ibHfXx8NGPGDM2YMaPJmrCwMC1btuyq79OzZ0/98Y9/vGrNU089paeeeurqDQMAgBapRT1dBQAAWg5CDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRbvmQk5ubq65duyooKEiJiYnasWOHt1sCAAA3gVs65KxYsUJZWVmaNm2adu/erV69esnhcOj48ePebg0AAHjZLR1y5s6dq3HjxmnMmDGKj49XXl6eQkJCtHjxYm+3BgAAvMzf2w1cq9raWpWVlWnKlCnWPl9fXyUlJam0tLTRY2pqalRTU2O9rq6uliS5XK7r6qW+5ovrOv6rdr3n81VibZp2M63NzbQuEmtzNaxN01ibxt1M6yJ9NWvTMIfb7b56ofsW9be//c0tyV1SUuKxf9KkSe5+/fo1esy0adPcktjY2NjY2NgM2CorK6+aFW7ZKznXYsqUKcrKyrJe19fX69SpU+rQoYN8fHy82Nk/Uml0dLQqKytls9m82svNhrVpGmvTNNamcaxL01ibpt1sa+N2u/X5558rKirqqnW3bMjp2LGj/Pz8VFVV5bG/qqpKkZGRjR4TGBiowMBAj33t2rW7US1eE5vNdlP8B3QzYm2axto0jbVpHOvSNNamaTfT2oSGhv7Lmlv2xuOAgAAlJCSouLjY2ldfX6/i4mLZ7XYvdgYAAG4Gt+yVHEnKyspSamqq+vbtq379+mn+/Pk6d+6cxowZ4+3WAACAl93SIWfEiBE6ceKEsrOz5XQ61bt3bxUWFioiIsLbrTVbYGCgpk2bdsWv08DaXA1r0zTWpnGsS9NYm6bdqmvj43b/q+evAAAAbj237D05AAAAV0PIAQAARiLkAAAAIxFyAACAkQg5uCVwfzwAoLlu6UfI0XIEBgbqww8/VFxcnLdbwU3o5MmTWrx4sUpLS+V0OiVJkZGRuu+++/Tcc8/ptttu83KHALyBR8i95Pz58yorK1NYWJji4+M9xi5cuKCVK1fq2Wef9VJ33nP5d4tdLicnR88884w6dOggSZo7d+7X2dZN6dy5c1q5cqWOHDmiTp066emnn7bWpyXZuXOnHA6HQkJClJSUZH1OVlVVlYqLi/XFF1+oqKhIffv29XKnN6fKykpNmzZNixcv9nYrX6vdu3erffv2io2NlST99re/VV5enioqKhQTE6OMjAyNHDnSy116z4EDB7Rt2zbZ7XZ1795dBw8eVE5OjmpqavTMM89o8ODB3m7xSyHkeMEnn3yiIUOGqKKiQj4+PhowYICWL1+uTp06SfrHD+eoqChdunTJy51+/Xx9fdWrV68rvlNs8+bN6tu3r1q3bi0fHx9t3LjROw16UXx8vP70pz8pLCxMlZWVevDBB3X69Gndeeed+vTTT+Xv769t27ZZP7Rbiv79+6tXr17Ky8u74ot23W63xo8fr48++kilpaVe6vDm9uGHH6pPnz4t7udNr169NGfOHCUlJWnRokX6/ve/r3HjxikuLk6HDh3SokWLlJOTo7Fjx3q71a9dYWGhhg0bpjZt2uiLL77Qu+++q2effVa9evVSfX29Nm/erPXr198SQYeQ4wWPP/646urqlJ+frzNnzmjixInav3+/Nm3apC5durTokPPaa6/pzTff1KJFizz+B2rVqpU+/PDDK656tSS+vr5yOp0KDw/XM888o6NHj2rdunUKDQ3V2bNn9fjjj+u2227TsmXLvN3q1yo4OFh79uxR9+7dGx0/ePCg7rnnHp0/f/5r7uzmsHr16quO//nPf9YPfvCDFvfzJiQkRAcOHFBMTIz69OmjCRMmaNy4cdb4smXL9JOf/ET79u3zYpfecd9992nw4MF69dVXtXz5cv3Hf/yHJkyYoJ/85CeSpClTpqisrEzr16/3cqdfghtfu/DwcPdHH31kva6vr3ePHz/e3aVLF/enn37qdjqdbl9fXy926F07duxw33nnne4f/OAH7traWrfb7Xb7+/u79+3b5+XOvMvHx8ddVVXldrvd7m984xvu9evXe4xv3brVHR0d7Y3WvKpr167upUuXNjm+dOlSd0xMzNfX0E3Gx8fH7evr6/bx8Wlya4k/bzp06ODetWuX2+3+x8/k8vJyj/EjR464g4ODvdGa19lsNvfhw4fdbrfbfenSJbe/v7979+7d1vjevXvdERER3mqvWXi6ygvOnz8vf///v+fbx8dHb7zxhr7zne/ooYce0ieffOLF7rzv3nvvVVlZmU6cOKG+ffvq448/vuLXEC1VwzpcuHDB+vVmg9tvv10nTpzwRlte9fLLL+uFF17QSy+9pNWrV2v79u3avn27Vq9erZdeeknjx4/X5MmTvd2m13Tq1Em///3vVV9f3+i2e/dub7foFUOHDtUbb7whSXrooYf03//93x7jK1euVLdu3bzR2k2h4WeNr6+vgoKCFBoaao21bdtW1dXV3mqtWXi6ygu6d++uXbt2XfGk0IIFCyRJ//Zv/+aNtm4qbdq00dKlS7V8+XIlJSW1uEvpTXn44Yfl7+8vl8ulQ4cO6e6777bG/vrXv7bIG4/T09PVsWNHzZs3TwsXLrT+W/Hz81NCQoLy8/P13e9+18tdek9CQoLKyso0bNiwRsd9fHxa5Ec0/OxnP9P999+vhx56SH379tWcOXO0adMm656cbdu26d133/V2m17RtWtXHT58WN/85jclSaWlperSpYs1XlFRccU/sm5WhBwvePzxx/Vf//VfGj169BVjCxYsUH19vfLy8rzQ2c1n5MiRGjBggMrKyhQTE+Ptdrxq2rRpHq/btGnj8XrNmjV64IEHvs6WbhojRozQiBEjVFdXp5MnT0qSOnbsqFatWnm5M++bNGmSzp071+R4t27d9Ic//OFr7OjmEBUVpT179ui1117TmjVr5Ha7tWPHDlVWVur+++/X1q1bW+wTeRMmTPD4h+Xl/5iSpPfff/+WuOlY4sZjAABgKO7JAQAARiLkAAAAIxFyAACAkQg5AADASIQcAC3WwIEDNXHiRG+3AeAG4ekqAMbbtGmTBg0apNOnT3t8L9qpU6fUqlUrtW3b1nvNAbhh+JwcAC1WWFiYt1sAcAPx6yoAX6v6+nrNmjVLsbGxCg4OVq9evayP1N+0aZN8fHxUVFSke+65R8HBwRo8eLCOHz+u999/X3FxcbLZbPre976nL774wpqzpqZG3//+9xUeHq6goCANGDBAO3fulCT95S9/0aBBgyRJ7du3l4+Pj5577jlJV/666vTp03r22WfVvn17hYSEaOjQoTp8+LA1np+fr3bt2qmoqEhxcXFq06aNHnnkEX322Wc3eNUAXAtCDoCv1axZs/Sb3/xGeXl52rdvnzIzM/XMM89o8+bNVs306dO1YMEClZSUqLKyUt/97nc1f/58LVu2TAUFBVq/fr1++ctfWvWTJ0/W7373Oy1dulS7d+9Wt27d5HA4dOrUKUVHR+t3v/udJOnQoUP67LPPlJOT02hvzz33nHbt2qXVq1ertLRUbrdbjz76qOrq6qyaL774Qr/4xS/029/+Vlu2bFFFRYVefvnlG7RaAK6LF78cFEALc+HCBXdISIi7pKTEY39aWpr76aefdv/hD39wS3J/8MEH1tisWbPcktyffvqpte/f//3f3Q6Hw+12u91nz551t2rVyv3OO+9Y47W1te6oqCj37Nmz3W6325r39OnTHu/70EMPuV966SW32+12f/LJJ25J7q1bt1rjJ0+edAcHB7tXrlzpdrvd7iVLlrgluY8cOWLV5Obm3jLfyAy0NNyTA+Brc+TIEX3xxRf69re/7bG/trZW99xzj/W6Z8+e1p8jIiIUEhKib3zjGx77duzYIUn69NNPVVdXp/vvv98ab9Wqlfr166cDBw586d4OHDggf39/JSYmWvs6dOigu+66y2OekJAQ64sLpX98y/fx48e/9PsA+PoQcgB8bc6ePStJKigo0O233+4xFhgYqE8//VSSPL5Y08fH54ov2vTx8VF9ff0N7rZxjfXi5iFV4KbEPTkAvjbx8fEKDAxURUWFunXr5rFFR0df05zf/OY3FRAQoK1bt1r76urqtHPnTsXHx0uSAgICJMnjm5X/WVxcnC5evKjt27db+/7+97/r0KFD1jwAbi1cyQHwtWnbtq1efvllZWZmqr6+XgMGDFB1dbW2bt0qm82mmJiYZs/ZunVrTZgwQZMmTVJYWJi6dOmi2bNn64svvlBaWpokKSYmRj4+Plq7dq0effRRBQcHq02bNh7z3HHHHRo2bJjGjRunX/3qV2rbtq1eeeUV3X777Ro2bNhXcv4Avl5cyQHwtZo5c6b+8z//U7NmzVJcXJweeeQRFRQUKDY29prnfO2115SSkqLRo0erT58+OnLkiIqKitS+fXtJ0u23364f//jHeuWVVxQREaGMjIxG51myZIkSEhL02GOPyW63y+12a926dVf8igrArYFPPAYAAEbiSg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjPR/DsjJFSOIL8kAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "big.emotion.value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9656fb13",
      "metadata": {
        "id": "9656fb13"
      },
      "outputs": [],
      "source": [
        "TrainingData = small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87deac1b",
      "metadata": {
        "id": "87deac1b"
      },
      "outputs": [],
      "source": [
        "TrainingData = TrainingData.iloc[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a458fcbd",
      "metadata": {
        "id": "a458fcbd"
      },
      "outputs": [],
      "source": [
        "TrainingData = TrainingDataCheckPoint.drop_duplicates().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a7877e0",
      "metadata": {
        "id": "1a7877e0"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomStandardScaler(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, mu: float, sigma: float):\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "        self.__mean = None\n",
        "        self.__std = None\n",
        "        self.__fitted = False\n",
        "\n",
        "    @property\n",
        "    def _fitted(self)->bool:\n",
        "        return self.__fitted\n",
        "\n",
        "    @_fitted.setter\n",
        "    def _fitted(self, value: bool):\n",
        "        if self.__fitted:\n",
        "            raise AttributeError(\"The 'fit' method has already been called.\")\n",
        "        if not isinstance(value, bool):\n",
        "            raise TypeError(\"The 'fitted' attribute must be a boolean.\")\n",
        "        self.__fitted = value\n",
        "\n",
        "    @property\n",
        "    def _mean(self)->np.ndarray:\n",
        "        '''\n",
        "        mean of the passed data\n",
        "        '''\n",
        "        if self.__mean is None:\n",
        "            raise AttributeError(\"The 'fit' method must be called before accessing the mean.\")\n",
        "        return self.__mean\n",
        "\n",
        "    @property\n",
        "    def _std(self)->np.ndarray:\n",
        "        '''\n",
        "        std of the passed data\n",
        "        '''\n",
        "        if self.__std is None:\n",
        "            raise AttributeError(\"The 'fit' method must be called before accessing the std.\")\n",
        "        return self.__std\n",
        "\n",
        "    def fit(self, X: np.ndarray)-> 'CustomStandardScaler':\n",
        "        self._fitted = True\n",
        "        self.__mean = X.mean(axis=0)\n",
        "        self.__std = X.std(axis=0)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: np.ndarray)-> np.ndarray:\n",
        "        newX = X - self._mean\n",
        "        newX = (newX / self._std) * self.sigma\n",
        "        return newX+self.mu\n",
        "\n",
        "    def fit_transform(self, X:np.ndarray) -> np.ndarray:\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "    def inverse_transform(self, X:np.ndarray) -> np.ndarray:\n",
        "        newX = X - self.mu\n",
        "        newX = (newX / self._std) * self.sigma\n",
        "        return newX + self._mean\n",
        "\n",
        "class CustomMinMaxScaler(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
        "    def __init__(self):\n",
        "        self.__min = None\n",
        "        self.__max = None\n",
        "        self.__fitted = False\n",
        "\n",
        "    @property\n",
        "    def _fitted(self)->bool:\n",
        "        return self.__fitted\n",
        "\n",
        "    @_fitted.setter\n",
        "    def _fitted(self, value: bool):\n",
        "        if self.__fitted:\n",
        "            raise AttributeError(\"The 'fit' method has already been called.\")\n",
        "        if not isinstance(value, bool):\n",
        "            raise TypeError(\"The 'fitted' attribute must be a boolean.\")\n",
        "        self.__fitted = value\n",
        "\n",
        "    @property\n",
        "    def _min(self)->np.ndarray:\n",
        "        '''\n",
        "        min of the passed data\n",
        "        '''\n",
        "        if self.__min is None:\n",
        "            raise AttributeError(\"The 'fit' method must be called before accessing the min.\")\n",
        "        return self.__min\n",
        "\n",
        "    @property\n",
        "    def _max(self)->np.ndarray:\n",
        "        '''\n",
        "        max of the passed data\n",
        "        '''\n",
        "        if self.__max is None:\n",
        "            raise AttributeError(\"The 'fit' method must be called before accessing the max.\")\n",
        "        return self.__max\n",
        "\n",
        "    def fit(self, X: np.ndarray)-> 'CustomStandardScaler':\n",
        "        self._fitted = True\n",
        "        self.__min = X.min(axis=0)\n",
        "        self.__max = X.max(axis=0)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: np.ndarray)-> np.ndarray:\n",
        "        return (X - self._min)/(self._max - self._min)\n",
        "\n",
        "    def fit_transform(self, X:np.ndarray) -> np.ndarray:\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "    def inverse_transform(self, X:np.ndarray) -> np.ndarray:\n",
        "        return X * (self._max - self._min) + self._min\n",
        "\n",
        "class Data(Dataset):\n",
        "    _identityFunc = lambda x: x\n",
        "    def __init__(self,data:pd.DataFrame, transform:transforms = None, scaler:BaseEstimator = None):\n",
        "        # making them private so can't be altered\n",
        "        if not scaler:\n",
        "            scaler = CustomScaler(0, 0.25)\n",
        "\n",
        "        self.__transform = transform if transform else Data._identityFunc\n",
        "        self.__Y = data['emotion'].astype(int).values.tolist()\n",
        "        self.__X = data.pixels.str.split().explode().astype(np.uint8).values.reshape(-1,48,48)\n",
        "        self.__len = data.shape[0]\n",
        "        try:\n",
        "            self.__X = scaler.fit_transform(self.__X).astype(np.float32)\n",
        "        except AttributeError:\n",
        "            print(\"Already fit\")\n",
        "            self.__X = scaler.transform(self.__X).astype(np.float32)\n",
        "\n",
        "    def __len__(self)->int:\n",
        "        return self.__len\n",
        "\n",
        "    def __getitem__(self, index)->tuple[np.ndarray,np.ndarray]:\n",
        "        img:np.ndarray = self.__X[index]\n",
        "        emotion:int = self.__Y[index]\n",
        "        label = np.zeros((7,), dtype=np.float32)\n",
        "        label[emotion] = 1\n",
        "        return self.__transform(img), label\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(32 * 12 * 12, 256),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(256, 100),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(100, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "135cd1e9",
      "metadata": {
        "id": "135cd1e9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # get accuracy\n",
        "        predicted = outputs.argmax(axis=1)\n",
        "        target = labels.argmax(axis=1)\n",
        "        correct = (predicted == target).sum().item()\n",
        "        accuracy = correct / labels.size(0)\n",
        "    return running_loss / len(dataloader), accuracy\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "      for images, labels in dataloader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          running_loss += loss.item()\n",
        "          predicted = outputs.argmax(axis=1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels.argmax(axis = 1)).sum().item()\n",
        "\n",
        "    return running_loss / len(dataloader), correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f5fce7e",
      "metadata": {
        "id": "0f5fce7e"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    '''\n",
        "    nn.CrossEntropyLosss is annoying me the way it expects labels\n",
        "    it also does the softmax part itself.\n",
        "\n",
        "    this class expects two R^n vectors or two arrays of R^n vectors\n",
        "    it then penalises the difference using negative log liklihood\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "    def forward(self, probabilites:torch.Tensor, target:torch.Tensor)->torch.Tensor:\n",
        "        '''\n",
        "        probabilites: R^n\n",
        "        target: R^n\n",
        "        '''\n",
        "        # print(probabilites)\n",
        "        # print(target)\n",
        "        # print(probabilites.shape)\n",
        "        # print(target.shape)\n",
        "        return -torch.sum(target * torch.log(probabilites + 1e-10), dim=1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cacbb424",
      "metadata": {
        "id": "cacbb424",
        "outputId": "df5e84aa-2eb3-40d3-d5a5-b7b236b9a230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fitting scaler\n",
            "making dataset\n",
            "Already fit\n",
            "Already fit\n",
            "making dataloader\n",
            "making model\n",
            "backward\n",
            "Epoch [1/100],     Train Loss: 1.9439,     Train Accuracy: 0.1427,     Test Loss: 2.0306,     Accuracy: 0.2505\n",
            "Epoch [2/100],     Train Loss: 2.0309,     Train Accuracy: 0.2505,     Test Loss: 1.8869,     Accuracy: 0.1461\n",
            "Epoch [3/100],     Train Loss: 1.8874,     Train Accuracy: 0.1466,     Test Loss: 1.8172,     Accuracy: 0.2505\n",
            "Epoch [4/100],     Train Loss: 1.8174,     Train Accuracy: 0.2505,     Test Loss: 1.8081,     Accuracy: 0.2505\n",
            "Epoch [5/100],     Train Loss: 1.8083,     Train Accuracy: 0.2505,     Test Loss: 1.8129,     Accuracy: 0.2505\n",
            "Epoch [6/100],     Train Loss: 1.8129,     Train Accuracy: 0.2505,     Test Loss: 1.8066,     Accuracy: 0.2505\n",
            "Epoch [7/100],     Train Loss: 1.8067,     Train Accuracy: 0.2505,     Test Loss: 1.8068,     Accuracy: 0.2505\n",
            "Epoch [8/100],     Train Loss: 1.8068,     Train Accuracy: 0.2505,     Test Loss: 1.7969,     Accuracy: 0.2505\n",
            "Epoch [9/100],     Train Loss: 1.7970,     Train Accuracy: 0.2505,     Test Loss: 1.8001,     Accuracy: 0.2549\n",
            "Epoch [10/100],     Train Loss: 1.8003,     Train Accuracy: 0.2530,     Test Loss: 1.7929,     Accuracy: 0.2510\n",
            "Epoch [11/100],     Train Loss: 1.7931,     Train Accuracy: 0.2516,     Test Loss: 1.7985,     Accuracy: 0.2517\n",
            "Epoch [12/100],     Train Loss: 1.7985,     Train Accuracy: 0.2504,     Test Loss: 1.7893,     Accuracy: 0.2529\n",
            "Epoch [13/100],     Train Loss: 1.7896,     Train Accuracy: 0.2525,     Test Loss: 1.7881,     Accuracy: 0.2547\n",
            "Epoch [14/100],     Train Loss: 1.7885,     Train Accuracy: 0.2550,     Test Loss: 1.7822,     Accuracy: 0.2506\n",
            "Epoch [15/100],     Train Loss: 1.7826,     Train Accuracy: 0.2512,     Test Loss: 1.7791,     Accuracy: 0.2505\n",
            "Epoch [16/100],     Train Loss: 1.7796,     Train Accuracy: 0.2506,     Test Loss: 1.7773,     Accuracy: 0.2512\n",
            "Epoch [17/100],     Train Loss: 1.7779,     Train Accuracy: 0.2515,     Test Loss: 1.7693,     Accuracy: 0.2534\n",
            "Epoch [18/100],     Train Loss: 1.7703,     Train Accuracy: 0.2543,     Test Loss: 1.7685,     Accuracy: 0.2650\n",
            "Epoch [19/100],     Train Loss: 1.7699,     Train Accuracy: 0.2638,     Test Loss: 1.7624,     Accuracy: 0.2627\n",
            "Epoch [20/100],     Train Loss: 1.7640,     Train Accuracy: 0.2648,     Test Loss: 1.7644,     Accuracy: 0.2502\n",
            "Epoch [21/100],     Train Loss: 1.7660,     Train Accuracy: 0.2533,     Test Loss: 1.7551,     Accuracy: 0.2650\n",
            "Epoch [22/100],     Train Loss: 1.7569,     Train Accuracy: 0.2660,     Test Loss: 1.7556,     Accuracy: 0.2731\n",
            "Epoch [23/100],     Train Loss: 1.7572,     Train Accuracy: 0.2731,     Test Loss: 1.7470,     Accuracy: 0.2666\n",
            "Epoch [24/100],     Train Loss: 1.7490,     Train Accuracy: 0.2698,     Test Loss: 1.7458,     Accuracy: 0.2623\n",
            "Epoch [25/100],     Train Loss: 1.7480,     Train Accuracy: 0.2665,     Test Loss: 1.7350,     Accuracy: 0.2784\n",
            "Epoch [26/100],     Train Loss: 1.7377,     Train Accuracy: 0.2802,     Test Loss: 1.7299,     Accuracy: 0.2917\n",
            "Epoch [27/100],     Train Loss: 1.7332,     Train Accuracy: 0.2910,     Test Loss: 1.7187,     Accuracy: 0.3023\n",
            "Epoch [28/100],     Train Loss: 1.7228,     Train Accuracy: 0.3009,     Test Loss: 1.7130,     Accuracy: 0.3004\n",
            "Epoch [29/100],     Train Loss: 1.7176,     Train Accuracy: 0.3011,     Test Loss: 1.7045,     Accuracy: 0.3103\n",
            "Epoch [30/100],     Train Loss: 1.7091,     Train Accuracy: 0.3085,     Test Loss: 1.6932,     Accuracy: 0.3147\n",
            "Epoch [31/100],     Train Loss: 1.6980,     Train Accuracy: 0.3165,     Test Loss: 1.6818,     Accuracy: 0.3208\n",
            "Epoch [32/100],     Train Loss: 1.6863,     Train Accuracy: 0.3233,     Test Loss: 1.6710,     Accuracy: 0.3312\n",
            "Epoch [33/100],     Train Loss: 1.6752,     Train Accuracy: 0.3321,     Test Loss: 1.6562,     Accuracy: 0.3435\n",
            "Epoch [34/100],     Train Loss: 1.6608,     Train Accuracy: 0.3448,     Test Loss: 1.6420,     Accuracy: 0.3518\n",
            "Epoch [35/100],     Train Loss: 1.6476,     Train Accuracy: 0.3515,     Test Loss: 1.6332,     Accuracy: 0.3541\n",
            "Epoch [36/100],     Train Loss: 1.6391,     Train Accuracy: 0.3545,     Test Loss: 1.6243,     Accuracy: 0.3625\n",
            "Epoch [37/100],     Train Loss: 1.6304,     Train Accuracy: 0.3623,     Test Loss: 1.6132,     Accuracy: 0.3721\n",
            "Epoch [38/100],     Train Loss: 1.6190,     Train Accuracy: 0.3690,     Test Loss: 1.6025,     Accuracy: 0.3631\n",
            "Epoch [39/100],     Train Loss: 1.6092,     Train Accuracy: 0.3642,     Test Loss: 1.5886,     Accuracy: 0.3803\n",
            "Epoch [40/100],     Train Loss: 1.5945,     Train Accuracy: 0.3786,     Test Loss: 1.5858,     Accuracy: 0.3898\n",
            "Epoch [41/100],     Train Loss: 1.5925,     Train Accuracy: 0.3855,     Test Loss: 1.5801,     Accuracy: 0.3770\n",
            "Epoch [42/100],     Train Loss: 1.5853,     Train Accuracy: 0.3776,     Test Loss: 1.5701,     Accuracy: 0.3965\n",
            "Epoch [43/100],     Train Loss: 1.5758,     Train Accuracy: 0.3930,     Test Loss: 1.5625,     Accuracy: 0.3934\n",
            "Epoch [44/100],     Train Loss: 1.5711,     Train Accuracy: 0.3906,     Test Loss: 1.5448,     Accuracy: 0.4042\n",
            "Epoch [45/100],     Train Loss: 1.5516,     Train Accuracy: 0.4006,     Test Loss: 1.5527,     Accuracy: 0.3972\n",
            "Epoch [46/100],     Train Loss: 1.5564,     Train Accuracy: 0.3956,     Test Loss: 1.5349,     Accuracy: 0.4078\n",
            "Epoch [47/100],     Train Loss: 1.5408,     Train Accuracy: 0.4049,     Test Loss: 1.5277,     Accuracy: 0.4113\n",
            "Epoch [48/100],     Train Loss: 1.5356,     Train Accuracy: 0.4093,     Test Loss: 1.5230,     Accuracy: 0.4122\n",
            "Epoch [49/100],     Train Loss: 1.5299,     Train Accuracy: 0.4103,     Test Loss: 1.5142,     Accuracy: 0.4117\n"
          ]
        }
      ],
      "source": [
        "transformers = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "print('fitting scaler')\n",
        "scaler = CustomStandardScaler(0, 0.25) #<- Pretty good - 37% accuracy on test set, 95% on training set\n",
        "\n",
        "scaler.fit(TrainingData.pixels.str.split().explode().astype(np.uint8).values.reshape(-1,48,48))\n",
        "\n",
        "print('making dataset')\n",
        "train_data = Data(TrainingData, transform=transformers, scaler=scaler)\n",
        "test_data = Data(FinalTestData, transform=transformers, scaler=scaler)\n",
        "\n",
        "print('making dataloader')\n",
        "train_loader = DataLoader(train_data, shuffle = True, batch_size=503370)\n",
        "test_loader = DataLoader(test_data, batch_size=7178, shuffle = True)\n",
        "\n",
        "print('making model')\n",
        "num_classes = 7\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN(num_classes).to(device)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = CustomLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=.01)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "print('backward')\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
        "    test_loss, accuracy = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \\\n",
        "    Train Loss: {train_loss:.4f}, \\\n",
        "    Train Accuracy: {train_accuracy:.4f}, \\\n",
        "    Test Loss: {test_loss:.4f}, \\\n",
        "    Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee4963b",
      "metadata": {
        "id": "3ee4963b",
        "outputId": "705350f8-49f2-46b6-dd80-15e5308e9d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fitting scaler\n",
            "making dataset\n",
            "Already fit\n",
            "Already fit\n",
            "making dataloader\n",
            "making model\n",
            "backward\n",
            "Epoch [1/100],     Train Loss: 2.0129,     Train Accuracy: 0.1428,     Test Loss: 2.1385,     Accuracy: 0.1728\n",
            "Epoch [2/100],     Train Loss: 2.2200,     Train Accuracy: 0.1429,     Test Loss: 1.9417,     Accuracy: 0.1694\n",
            "Epoch [3/100],     Train Loss: 1.9575,     Train Accuracy: 0.1428,     Test Loss: 1.9852,     Accuracy: 0.0152\n",
            "Epoch [4/100],     Train Loss: 1.9497,     Train Accuracy: 0.1428,     Test Loss: 1.9615,     Accuracy: 0.1427\n",
            "Epoch [5/100],     Train Loss: 1.9488,     Train Accuracy: 0.1428,     Test Loss: 1.9408,     Accuracy: 0.1427\n",
            "Epoch [6/100],     Train Loss: 1.9472,     Train Accuracy: 0.1428,     Test Loss: 1.9292,     Accuracy: 0.2350\n",
            "Epoch [7/100],     Train Loss: 1.9465,     Train Accuracy: 0.1490,     Test Loss: 1.9344,     Accuracy: 0.2545\n",
            "Epoch [8/100],     Train Loss: 1.9489,     Train Accuracy: 0.1471,     Test Loss: 1.9481,     Accuracy: 0.0318\n",
            "Epoch [9/100],     Train Loss: 1.9479,     Train Accuracy: 0.1477,     Test Loss: 1.9575,     Accuracy: 0.0280\n",
            "Epoch [10/100],     Train Loss: 1.9459,     Train Accuracy: 0.1541,     Test Loss: 1.9574,     Accuracy: 0.1383\n",
            "Epoch [11/100],     Train Loss: 1.9456,     Train Accuracy: 0.1487,     Test Loss: 1.9511,     Accuracy: 0.1428\n",
            "Epoch [12/100],     Train Loss: 1.9461,     Train Accuracy: 0.1436,     Test Loss: 1.9447,     Accuracy: 0.1339\n",
            "Epoch [13/100],     Train Loss: 1.9443,     Train Accuracy: 0.1696,     Test Loss: 1.9393,     Accuracy: 0.1519\n",
            "Epoch [14/100],     Train Loss: 1.9430,     Train Accuracy: 0.1700,     Test Loss: 1.9318,     Accuracy: 0.2516\n",
            "Epoch [15/100],     Train Loss: 1.9411,     Train Accuracy: 0.1565,     Test Loss: 1.9263,     Accuracy: 0.1721\n",
            "Epoch [16/100],     Train Loss: 1.9404,     Train Accuracy: 0.1503,     Test Loss: 1.9348,     Accuracy: 0.2435\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[130], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 30\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m    Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m    Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m    Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m    Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[122], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[1;32md:\\Program Files\\Python312\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Program Files\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Program Files\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "transformers = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "print('fitting scaler')\n",
        "scaler = CustomMinMaxScaler()\n",
        "\n",
        "scaler.fit(TrainingData.pixels.str.split().explode().astype(np.uint8).values.reshape(-1,48,48))\n",
        "\n",
        "print('making dataset')\n",
        "train_data = Data(TrainingData, transform=transformers, scaler=scaler)\n",
        "test_data = Data(FinalTestData, transform=transformers, scaler=scaler)\n",
        "\n",
        "print('making dataloader')\n",
        "train_loader = DataLoader(train_data, shuffle = True, batch_size=503370)\n",
        "test_loader = DataLoader(test_data, batch_size=7178, shuffle = True)\n",
        "\n",
        "print('making model')\n",
        "num_classes = 7\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN(num_classes).to(device)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = CustomLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=.01)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "print('backward')\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
        "    test_loss, accuracy = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \\\n",
        "    Train Loss: {train_loss:.4f}, \\\n",
        "    Train Accuracy: {train_accuracy:.4f}, \\\n",
        "    Test Loss: {test_loss:.4f}, \\\n",
        "    Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9165f479",
      "metadata": {
        "id": "9165f479"
      },
      "outputs": [],
      "source": [
        "# for images, labels in train_loader:\n",
        "#     print(1)\n",
        "\n",
        "y = model(images).argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "849fe4c8",
      "metadata": {
        "id": "849fe4c8"
      },
      "outputs": [],
      "source": [
        "yhat = labels.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58eba753",
      "metadata": {
        "id": "58eba753",
        "outputId": "a196d93c-3715-4344-f67b-4a6f66553554"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4, 3, 2,  ..., 4, 3, 1])"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7acf837b",
      "metadata": {
        "id": "7acf837b",
        "outputId": "9f51013f-3c0f-4e2b-c052-90298bdc3af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9295788637266588"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(y == yhat).sum().item()/len(yhat)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}