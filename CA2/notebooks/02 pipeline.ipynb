{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8568a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing._data import BaseEstimator, TransformerMixin, OneToOneFeatureMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20112027",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = pd.read_pickle('../data/02 Processed/train.pkl')\n",
    "FinalTestData = pd.read_pickle('../data/02 Processed/testData.pkl')\n",
    "FinalTestData.drop(columns = 'usage', inplace = True)\n",
    "# s = TrainingData.iloc[:1000].copy()\n",
    "# del TrainingData\n",
    "# TrainingData = s.copy()\n",
    "# del s\n",
    "\n",
    "FinalTestData.shape, TrainingData.shape\n",
    "TrainingDataCheckPoint = TrainingData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a6d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "big,small = train_test_split(TrainingData, test_size=0.02, stratify=TrainingData['emotion'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c602de3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='emotion'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small.emotion.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27394554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='emotion'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "big.emotion.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9656fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "87deac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = TrainingData.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a458fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1a7877e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, mu: float, sigma: float):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.__mean = None\n",
    "        self.__std = None\n",
    "        self.__fitted = False\n",
    "    \n",
    "    @property\n",
    "    def _fitted(self)->bool:\n",
    "        return self.__fitted\n",
    "    \n",
    "    @_fitted.setter\n",
    "    def _fitted(self, value: bool):\n",
    "        if self.__fitted:\n",
    "            raise AttributeError(\"The 'fit' method has already been called.\")\n",
    "        if not isinstance(value, bool):\n",
    "            raise TypeError(\"The 'fitted' attribute must be a boolean.\")\n",
    "        self.__fitted = value\n",
    "\n",
    "    @property\n",
    "    def _mean(self)->np.ndarray:\n",
    "        '''\n",
    "        mean of the passed data\n",
    "        '''\n",
    "        if self.__mean is None:\n",
    "            raise AttributeError(\"The 'fit' method must be called before accessing the mean.\")\n",
    "        return self.__mean\n",
    "    \n",
    "    @property\n",
    "    def _std(self)->np.ndarray:\n",
    "        '''\n",
    "        std of the passed data\n",
    "        '''\n",
    "        if self.__std is None:\n",
    "            raise AttributeError(\"The 'fit' method must be called before accessing the std.\")\n",
    "        return self.__std\n",
    "\n",
    "    def fit(self, X: np.ndarray)-> 'CustomScaler':\n",
    "        self._fitted = True\n",
    "        self.__mean = X.mean(axis=0)\n",
    "        self.__std = X.std(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: np.ndarray)-> np.ndarray:\n",
    "        newX = X - self._mean\n",
    "        newX = (newX / self._std) * self.sigma\n",
    "        return newX+self.mu\n",
    "\n",
    "    def fit_transform(self, X:np.ndarray) -> np.ndarray:\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def inverse_transform(self, X:np.ndarray) -> np.ndarray:\n",
    "        newX = X - self.mu\n",
    "        newX = (newX / self._std) * self.sigma\n",
    "        return newX + self._mean\n",
    "\n",
    "class Data(Dataset):\n",
    "    _identityFunc = lambda x: x\n",
    "    def __init__(self,data:pd.DataFrame, transform:transforms = None, scaler:BaseEstimator = None):\n",
    "        # making them private so can't be altered\n",
    "        if not scaler:\n",
    "            scaler = CustomScaler(0, 0.25)\n",
    "\n",
    "        self.__transform = transform if transform else Data._identityFunc\n",
    "        self.__Y = data['emotion'].astype(int).values.tolist()\n",
    "        self.__X = data.pixels.str.split().explode().astype(np.uint8).values.reshape(-1,48,48)\n",
    "        self.__len = data.shape[0]\n",
    "        try:\n",
    "            self.__X = scaler.fit_transform(self.__X).astype(np.float32)\n",
    "        except AttributeError:\n",
    "            print(\"Already fit\")\n",
    "            self.__X = scaler.transform(self.__X).astype(np.float32)\n",
    "\n",
    "    def __len__(self)->int:\n",
    "        return self.__len\n",
    "\n",
    "    def __getitem__(self, index)->tuple[np.ndarray,np.ndarray]:\n",
    "        img:np.ndarray = self.__X[index]\n",
    "        emotion:int = self.__Y[index]\n",
    "        label = np.zeros((7,), dtype=np.float32)\n",
    "        label[emotion] = 1\n",
    "        return self.__transform(img), label\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32 * 12 * 12, 256),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 100),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(100, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "135cd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # get accuracy\n",
    "        predicted = outputs.argmax(axis=1)\n",
    "        target = labels.argmax(axis=1)\n",
    "        correct = (predicted == target).sum().item()\n",
    "        accuracy = correct / labels.size(0)\n",
    "    return running_loss / len(dataloader), accuracy\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      for images, labels in dataloader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "          running_loss += loss.item()\n",
    "          predicted = outputs.argmax(axis=1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels.argmax(axis = 1)).sum().item()\n",
    "\n",
    "    return running_loss / len(dataloader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f5fce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    '''\n",
    "    nn.CrossEntropyLosss is annoying me the way it expects labels\n",
    "    it also does the softmax part itself.\n",
    "\n",
    "    this class expects two R^n vectors or two arrays of R^n vectors\n",
    "    it then penalises the difference using negative log liklihood\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "    def forward(self, probabilites:torch.Tensor, target:torch.Tensor)->torch.Tensor:\n",
    "        '''\n",
    "        probabilites: R^n\n",
    "        target: R^n\n",
    "        '''\n",
    "        # print(probabilites)\n",
    "        # print(target)\n",
    "        # print(probabilites.shape)\n",
    "        # print(target.shape)\n",
    "        return -torch.sum(target * torch.log(probabilites + 1e-10), dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbb424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting scaler\n",
      "making dataset\n",
      "Already fit\n",
      "Already fit\n",
      "making dataloader\n",
      "making model\n",
      "backward\n",
      "Epoch [1/100],     Train Loss: 1.9759,     Test Loss: 2.0018,     Accuracy: 0.2288\n",
      "Epoch [2/100],     Train Loss: 2.2109,     Test Loss: 1.9555,     Accuracy: 0.1115\n",
      "Epoch [3/100],     Train Loss: 1.9549,     Test Loss: 1.9796,     Accuracy: 0.0152\n",
      "Epoch [4/100],     Train Loss: 1.9487,     Test Loss: 1.9580,     Accuracy: 0.0152\n",
      "Epoch [5/100],     Train Loss: 1.9485,     Test Loss: 1.9412,     Accuracy: 0.2335\n",
      "Epoch [6/100],     Train Loss: 1.9454,     Test Loss: 1.9340,     Accuracy: 0.1861\n",
      "Epoch [7/100],     Train Loss: 1.9438,     Test Loss: 1.9321,     Accuracy: 0.1747\n",
      "Epoch [8/100],     Train Loss: 1.9420,     Test Loss: 1.9350,     Accuracy: 0.1651\n",
      "Epoch [9/100],     Train Loss: 1.9372,     Test Loss: 1.9383,     Accuracy: 0.1806\n",
      "Epoch [10/100],     Train Loss: 1.9287,     Test Loss: 1.9316,     Accuracy: 0.1780\n",
      "Epoch [11/100],     Train Loss: 1.9223,     Test Loss: 1.9225,     Accuracy: 0.1673\n",
      "Epoch [12/100],     Train Loss: 1.9154,     Test Loss: 1.8939,     Accuracy: 0.2158\n",
      "Epoch [13/100],     Train Loss: 1.9049,     Test Loss: 1.8720,     Accuracy: 0.2211\n",
      "Epoch [14/100],     Train Loss: 1.8967,     Test Loss: 1.8770,     Accuracy: 0.2069\n",
      "Epoch [15/100],     Train Loss: 1.8855,     Test Loss: 1.9101,     Accuracy: 0.1712\n",
      "Epoch [16/100],     Train Loss: 1.8796,     Test Loss: 1.8857,     Accuracy: 0.2173\n",
      "Epoch [17/100],     Train Loss: 1.8842,     Test Loss: 1.8768,     Accuracy: 0.1995\n",
      "Epoch [18/100],     Train Loss: 1.8684,     Test Loss: 1.8802,     Accuracy: 0.1982\n",
      "Epoch [19/100],     Train Loss: 1.8575,     Test Loss: 1.8590,     Accuracy: 0.2138\n",
      "Epoch [20/100],     Train Loss: 1.8509,     Test Loss: 1.8355,     Accuracy: 0.2208\n",
      "Epoch [21/100],     Train Loss: 1.8389,     Test Loss: 1.8681,     Accuracy: 0.1948\n",
      "Epoch [22/100],     Train Loss: 1.8302,     Test Loss: 1.8651,     Accuracy: 0.2091\n",
      "Epoch [23/100],     Train Loss: 1.8235,     Test Loss: 1.7986,     Accuracy: 0.2629\n",
      "Epoch [24/100],     Train Loss: 1.8101,     Test Loss: 1.7966,     Accuracy: 0.2577\n",
      "Epoch [25/100],     Train Loss: 1.8004,     Test Loss: 1.8369,     Accuracy: 0.2374\n",
      "Epoch [26/100],     Train Loss: 1.7897,     Test Loss: 1.8271,     Accuracy: 0.2363\n",
      "Epoch [27/100],     Train Loss: 1.7781,     Test Loss: 1.7752,     Accuracy: 0.2838\n",
      "Epoch [28/100],     Train Loss: 1.7660,     Test Loss: 1.8028,     Accuracy: 0.2588\n",
      "Epoch [29/100],     Train Loss: 1.7554,     Test Loss: 1.7954,     Accuracy: 0.2621\n",
      "Epoch [30/100],     Train Loss: 1.7459,     Test Loss: 1.7917,     Accuracy: 0.2781\n",
      "Epoch [31/100],     Train Loss: 1.7426,     Test Loss: 1.7437,     Accuracy: 0.3038\n",
      "Epoch [32/100],     Train Loss: 1.7271,     Test Loss: 1.7981,     Accuracy: 0.2662\n",
      "Epoch [33/100],     Train Loss: 1.7089,     Test Loss: 1.7613,     Accuracy: 0.2966\n",
      "Epoch [34/100],     Train Loss: 1.6944,     Test Loss: 1.7128,     Accuracy: 0.3309\n",
      "Epoch [35/100],     Train Loss: 1.6896,     Test Loss: 1.7724,     Accuracy: 0.2906\n",
      "Epoch [36/100],     Train Loss: 1.6630,     Test Loss: 1.7484,     Accuracy: 0.3098\n",
      "Epoch [37/100],     Train Loss: 1.6574,     Test Loss: 1.7301,     Accuracy: 0.3238\n",
      "Epoch [38/100],     Train Loss: 1.6487,     Test Loss: 1.7248,     Accuracy: 0.3378\n",
      "Epoch [39/100],     Train Loss: 1.6419,     Test Loss: 1.8136,     Accuracy: 0.2926\n",
      "Epoch [40/100],     Train Loss: 1.6429,     Test Loss: 1.7058,     Accuracy: 0.3275\n",
      "Epoch [41/100],     Train Loss: 1.5982,     Test Loss: 1.6934,     Accuracy: 0.3565\n",
      "Epoch [42/100],     Train Loss: 1.6115,     Test Loss: 1.7572,     Accuracy: 0.3162\n",
      "Epoch [43/100],     Train Loss: 1.5792,     Test Loss: 1.7297,     Accuracy: 0.3164\n",
      "Epoch [44/100],     Train Loss: 1.5708,     Test Loss: 1.7074,     Accuracy: 0.3363\n",
      "Epoch [45/100],     Train Loss: 1.5479,     Test Loss: 1.6615,     Accuracy: 0.3665\n",
      "Epoch [46/100],     Train Loss: 1.5343,     Test Loss: 1.7411,     Accuracy: 0.3327\n",
      "Epoch [47/100],     Train Loss: 1.5227,     Test Loss: 1.6700,     Accuracy: 0.3479\n",
      "Epoch [48/100],     Train Loss: 1.4985,     Test Loss: 1.7438,     Accuracy: 0.3303\n",
      "Epoch [49/100],     Train Loss: 1.5029,     Test Loss: 1.6196,     Accuracy: 0.3773\n",
      "Epoch [50/100],     Train Loss: 1.4785,     Test Loss: 1.7611,     Accuracy: 0.3285\n",
      "Epoch [51/100],     Train Loss: 1.4601,     Test Loss: 1.6831,     Accuracy: 0.3608\n",
      "Epoch [52/100],     Train Loss: 1.4179,     Test Loss: 1.6389,     Accuracy: 0.3734\n",
      "Epoch [53/100],     Train Loss: 1.4293,     Test Loss: 1.7033,     Accuracy: 0.3564\n",
      "Epoch [54/100],     Train Loss: 1.3853,     Test Loss: 1.7162,     Accuracy: 0.3461\n",
      "Epoch [55/100],     Train Loss: 1.3708,     Test Loss: 1.6636,     Accuracy: 0.3706\n",
      "Epoch [56/100],     Train Loss: 1.3413,     Test Loss: 1.7578,     Accuracy: 0.3433\n",
      "Epoch [57/100],     Train Loss: 1.3458,     Test Loss: 1.6145,     Accuracy: 0.3781\n",
      "Epoch [58/100],     Train Loss: 1.3836,     Test Loss: 1.8391,     Accuracy: 0.3215\n",
      "Epoch [59/100],     Train Loss: 1.3249,     Test Loss: 1.6948,     Accuracy: 0.3628\n",
      "Epoch [60/100],     Train Loss: 1.2579,     Test Loss: 1.6325,     Accuracy: 0.3767\n",
      "Epoch [61/100],     Train Loss: 1.2602,     Test Loss: 1.7166,     Accuracy: 0.3643\n",
      "Epoch [62/100],     Train Loss: 1.2212,     Test Loss: 1.7592,     Accuracy: 0.3592\n",
      "Epoch [63/100],     Train Loss: 1.1939,     Test Loss: 1.6823,     Accuracy: 0.3661\n",
      "Epoch [64/100],     Train Loss: 1.1849,     Test Loss: 1.7111,     Accuracy: 0.3671\n",
      "Epoch [65/100],     Train Loss: 1.1408,     Test Loss: 1.7340,     Accuracy: 0.3647\n",
      "Epoch [66/100],     Train Loss: 1.1113,     Test Loss: 1.7529,     Accuracy: 0.3615\n",
      "Epoch [67/100],     Train Loss: 1.0935,     Test Loss: 1.7865,     Accuracy: 0.3519\n",
      "Epoch [68/100],     Train Loss: 1.1016,     Test Loss: 1.9049,     Accuracy: 0.3306\n",
      "Epoch [69/100],     Train Loss: 1.2017,     Test Loss: 1.6698,     Accuracy: 0.3760\n",
      "Epoch [70/100],     Train Loss: 1.1475,     Test Loss: 1.8571,     Accuracy: 0.3462\n",
      "Epoch [71/100],     Train Loss: 1.1199,     Test Loss: 1.8968,     Accuracy: 0.3357\n",
      "Epoch [72/100],     Train Loss: 1.0693,     Test Loss: 1.7771,     Accuracy: 0.3618\n",
      "Epoch [73/100],     Train Loss: 1.0054,     Test Loss: 1.8299,     Accuracy: 0.3504\n",
      "Epoch [74/100],     Train Loss: 1.0399,     Test Loss: 1.7805,     Accuracy: 0.3653\n",
      "Epoch [75/100],     Train Loss: 0.9694,     Test Loss: 1.8230,     Accuracy: 0.3621\n",
      "Epoch [76/100],     Train Loss: 0.9155,     Test Loss: 1.9121,     Accuracy: 0.3408\n",
      "Epoch [77/100],     Train Loss: 0.9144,     Test Loss: 1.8436,     Accuracy: 0.3607\n",
      "Epoch [78/100],     Train Loss: 0.8791,     Test Loss: 1.8373,     Accuracy: 0.3656\n",
      "Epoch [79/100],     Train Loss: 0.8430,     Test Loss: 1.8946,     Accuracy: 0.3657\n",
      "Epoch [80/100],     Train Loss: 0.7965,     Test Loss: 1.9619,     Accuracy: 0.3536\n",
      "Epoch [81/100],     Train Loss: 0.7788,     Test Loss: 1.9073,     Accuracy: 0.3663\n",
      "Epoch [82/100],     Train Loss: 0.7445,     Test Loss: 1.9647,     Accuracy: 0.3515\n",
      "Epoch [83/100],     Train Loss: 0.7244,     Test Loss: 1.9887,     Accuracy: 0.3612\n",
      "Epoch [84/100],     Train Loss: 0.7413,     Test Loss: 2.1295,     Accuracy: 0.3342\n",
      "Epoch [85/100],     Train Loss: 0.7665,     Test Loss: 2.0942,     Accuracy: 0.3479\n",
      "Epoch [86/100],     Train Loss: 0.7112,     Test Loss: 1.9766,     Accuracy: 0.3729\n",
      "Epoch [87/100],     Train Loss: 0.6341,     Test Loss: 2.2467,     Accuracy: 0.3189\n",
      "Epoch [88/100],     Train Loss: 0.7032,     Test Loss: 2.0568,     Accuracy: 0.3628\n",
      "Epoch [89/100],     Train Loss: 0.5988,     Test Loss: 2.1034,     Accuracy: 0.3572\n",
      "Epoch [90/100],     Train Loss: 0.5722,     Test Loss: 2.1852,     Accuracy: 0.3370\n",
      "Epoch [91/100],     Train Loss: 0.5456,     Test Loss: 2.1084,     Accuracy: 0.3523\n",
      "Epoch [92/100],     Train Loss: 0.5068,     Test Loss: 2.1602,     Accuracy: 0.3566\n",
      "Epoch [93/100],     Train Loss: 0.5010,     Test Loss: 2.1795,     Accuracy: 0.3578\n",
      "Epoch [94/100],     Train Loss: 0.4476,     Test Loss: 2.2332,     Accuracy: 0.3481\n",
      "Epoch [95/100],     Train Loss: 0.4429,     Test Loss: 2.2364,     Accuracy: 0.3554\n",
      "Epoch [96/100],     Train Loss: 0.4006,     Test Loss: 2.2162,     Accuracy: 0.3635\n",
      "Epoch [97/100],     Train Loss: 0.3915,     Test Loss: 2.2812,     Accuracy: 0.3546\n",
      "Epoch [98/100],     Train Loss: 0.3503,     Test Loss: 2.3901,     Accuracy: 0.3380\n",
      "Epoch [99/100],     Train Loss: 0.3443,     Test Loss: 2.3460,     Accuracy: 0.3566\n",
      "Epoch [100/100],     Train Loss: 0.3108,     Test Loss: 2.3544,     Accuracy: 0.3614\n"
     ]
    }
   ],
   "source": [
    "transformers = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "print('fitting scaler')\n",
    "scaler = CustomScaler(0, 0.25) #<- Pretty good - 37% accuracy on test set, 95% on training set\n",
    "\n",
    "scaler.fit(TrainingData.pixels.str.split().explode().astype(np.uint8).values.reshape(-1,48,48))\n",
    "\n",
    "print('making dataset')\n",
    "train_data = Data(TrainingData, transform=transformers, scaler=scaler)\n",
    "test_data = Data(FinalTestData, transform=transformers, scaler=scaler)\n",
    "\n",
    "print('making dataloader')\n",
    "train_loader = DataLoader(train_data, shuffle = True, batch_size=503370)\n",
    "test_loader = DataLoader(test_data, batch_size=7178, shuffle = True)\n",
    "\n",
    "print('making model')\n",
    "num_classes = 7\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(num_classes).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = CustomLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "print('backward')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, accuracy = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \\\n",
    "    Train Loss: {train_loss:.4f}, \\\n",
    "    Test Loss: {test_loss:.4f}, \\\n",
    "    Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting scaler\n",
      "making dataset\n",
      "Already fit\n",
      "Already fit\n",
      "making dataloader\n",
      "making model\n",
      "backward\n",
      "Epoch [1/100],     Train Loss: 1.9550,     Test Loss: 2.2729,     Accuracy: 0.1427\n",
      "Epoch [2/100],     Train Loss: 2.2098,     Test Loss: 2.1075,     Accuracy: 0.0152\n",
      "Epoch [3/100],     Train Loss: 2.0309,     Test Loss: 1.9840,     Accuracy: 0.0152\n",
      "Epoch [4/100],     Train Loss: 1.9657,     Test Loss: 1.9238,     Accuracy: 0.2505\n",
      "Epoch [5/100],     Train Loss: 1.9596,     Test Loss: 1.8934,     Accuracy: 0.2505\n"
     ]
    }
   ],
   "source": [
    "transformers = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "print('fitting scaler')\n",
    "# scaler = CustomScaler(0, 0.25) #<- Pretty good - 37% accuracy on test set, 95% on training set\n",
    "scaler = CustomScaler(0.5, 0.125) #<- Pretty good - 37% accuracy on test set, 95% on training set\n",
    "\n",
    "scaler.fit(TrainingData.pixels.str.split().explode().astype(np.uint8).values.reshape(-1,48,48))\n",
    "\n",
    "print('making dataset')\n",
    "train_data = Data(TrainingData, transform=transformers, scaler=scaler)\n",
    "test_data = Data(FinalTestData, transform=transformers, scaler=scaler)\n",
    "\n",
    "print('making dataloader')\n",
    "train_loader = DataLoader(train_data, shuffle = True, batch_size=503370)\n",
    "test_loader = DataLoader(test_data, batch_size=7178, shuffle = True)\n",
    "\n",
    "print('making model')\n",
    "num_classes = 7\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(num_classes).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = CustomLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "print('backward')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, accuracy = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \\\n",
    "    Train Loss: {train_loss:.4f}, \\\n",
    "    Test Loss: {test_loss:.4f}, \\\n",
    "    Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ff818e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100],     Train Loss: 0.2712,     Train Accuracy: 0.9385,     Test Loss: 2.4787,     Accuracy: 0.3473\n",
      "Epoch [2/100],     Train Loss: 0.2572,     Train Accuracy: 0.9413,     Test Loss: 2.4999,     Accuracy: 0.3486\n",
      "Epoch [3/100],     Train Loss: 0.2374,     Train Accuracy: 0.9460,     Test Loss: 2.4694,     Accuracy: 0.3575\n",
      "Epoch [4/100],     Train Loss: 0.2201,     Train Accuracy: 0.9520,     Test Loss: 2.5346,     Accuracy: 0.3449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m    Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m    Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m    Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[122], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\Program Files\\Python312\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program Files\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program Files\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, accuracy = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \\\n",
    "    Train Loss: {train_loss:.4f}, \\\n",
    "    Train Accuracy: {train_accuracy:.4f}, \\\n",
    "    Test Loss: {test_loss:.4f}, \\\n",
    "    Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9165f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, labels in train_loader:\n",
    "#     print(1)\n",
    "\n",
    "y = model(images).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "849fe4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = labels.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "58eba753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 2,  ..., 4, 3, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7acf837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9295788637266588"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y == yhat).sum().item()/len(yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
